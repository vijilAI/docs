{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Aggressive Prompts in Vijil Evaluate\n",
    "\n",
    "This notebook goes through the construction of a test harness composed of the most aggressive prompts in Vijil Evaluate based on historical evaluations, and shows evaluation results of a few LLMs on this harness.\n",
    "\n",
    "## Method\n",
    "\n",
    "To construct this harness, we obtain aggregated detector scores for all prompts in Vijil Evaluate, with the following filters\n",
    "- Only non-null scores, leaving out errored generations\n",
    "- Evaluations created on or after 12/1/2024, to ensure freshness of the test harness and detection logic in light of regular internal updates\n",
    "- Prompts that are used in at least 5 evaluations, to ensure a baseline amount of stability in the average detector score.\n",
    "\n",
    "Given these filters, we extracted 598 prompts in total that have an average detector score of *at least 0.95*. Based on these prompts, we construct the harness `vijil.harnesses.most_aggressive`, clubbing them in their own probes and dimensions.\n",
    "\n",
    "The composition of prompts across our 8 dimensions of trust is as follows. Note that Stereotype is the only dimension that does not have any prompts in this set.\n",
    "\n",
    "| Dimension | No. of prompts |\n",
    "|---|---|\n",
    "|Security|407|\n",
    "|Privacy|50|\n",
    "|Robustness|14|\n",
    "|Hallucination|27|\n",
    "|Toxicity|66|\n",
    "|Stereotype|0|\n",
    "|Ethics|22|\n",
    "|Fairness|12|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The following code runs the harnesses containing these prompts in Vijil Evaluate. First you load the Vijil python client, with a `VIJIL_API_KEY` [fetched](https://docs.vijil.ai/setup.html) from the Evaluate frontend in your local .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U vijil\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from vijil import Vijil\n",
    "client = Vijil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = client.evaluations.create(\n",
    "    model_hub=\"together\",\n",
    "    model_name=\"deepseek-ai/DeepSeek-R1\",\n",
    "    harnesses=[\n",
    "        f\"{dim}_most_aggressive\"\n",
    "        for dim in [\"security\",\"privacy\",\"hallucination\",\"robustness\",\"toxicity\",\"fairness\",\"ethics\"]\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results of five canonical LLMs we tested this harness on. Generally, all LLMs perform poorly across dimensions. Among the five models here, OpenAI o1 performs the best, with an overall score of 36.12.\n",
    "\n",
    "| LLM | OpenAI gpt-4o-mini | OpenAI o1 | DeepSeek R1 | Llama 3.3 70B Instruct Turbo | Google Gemma 2 27B |\n",
    "|------|------------|----|--------------|-----------------------------|-------------------|\n",
    "| Security | 0.16 | 18.83 | 19.40 | 0.07 | 12.70 |\n",
    "| Privacy | 0.00 | 55.42 | 5.71 | 25.00 | 25.64 |\n",
    "| Robustness | 0.00 | 66.67 | 50.00 | 25.00 | 8.33 |\n",
    "| Hallucination | 2.78 | 26.85 | 38.89 | 5.00 | 43.33 |\n",
    "| Toxicity | 15.90 | 43.47 | 24.58 | 3.33 | 35.02 |\n",
    "| Ethics | 0.00 | 41.58 | 7.33 | 0.00 | 0.00 |\n",
    "| Fairness | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |\n",
    "| **Overall** | **2.69** | **36.12** | **20.84** | **8.34** | **17.86** |\n",
    "\n",
    "If you are adopting an LLM in an enterprise setting or building an agent with it, be sure to perform holistic adversarial testing before deployment and during CI/CD. To use Vijil's most aggressive prompts for this purpose sign up at https://evaluate.vijil.ai."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
