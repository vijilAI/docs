{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vijil Evaluate at-a-glance\n",
    "\n",
    "Vijil Evaluate is Vijilâ€™s flagship evaluation service that enables AI developers evaluate the trustworthiness of an LLM, generative AI application, or agent. Using the Evaluate API, developers can test an AI system under benign and hostile conditions in minutes for reliability, security, and safety.\n",
    "\n",
    "This notebook gives an overview of the major features in Vijil Evaluate through our Python client.\n",
    "\n",
    "## Getting Started\n",
    "To set up your local environment, follow the steps [here](https://docs.vijil.ai/setup.html) to install the Python client and get an API key for the Evaluate Platform.\n",
    "\n",
    "Once the Python client installed, you can instantiate a client class and store an API key for the provider your agent is hosted on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vijil import Vijil\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = Vijil()\n",
    "# client.api_keys.create(\n",
    "#     name=\"openai-test\", \n",
    "#     model_hub=\"openai\", \n",
    "#     api_key=\"sk+++\" # replace with your own api key\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to kick off an evaluation job!\n",
    "\n",
    "## Trust Score\n",
    "The following command kicks off a full trust evaluation job on GPT-4o-mini, setting temperature at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.evaluations.create(\n",
    "    model_hub=\"openai\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    model_params={\"temperature\": 0},\n",
    "    harnesses=[\"trust_score\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "For quickly testing an LLM or agent on well-known benchmarks, we have 21 benchmarks available across reliability (e.g. [OpenLLM](https://huggingface.co/open-llm-leaderboard), [OpenLLM v2](https://huggingface.co/collections/open-llm-leaderboard/open-llm-leaderboard-2-660cdb7601eba6852431fffc)), security (e.g. [garak](https://garak.ai/), [CyberSecEval 3](https://ai.meta.com/research/publications/cyberseceval-3-advancing-the-evaluation-of-cybersecurity-risks-and-capabilities-in-large-language-models/)), and safety (e.g. [StrongReject](https://arxiv.org/abs/2402.10260), [JailbreakBench](https://arxiv.org/abs/2404.01318)) in Vijil Evaluate.\n",
    "\n",
    "The following command lists available benchmarks in Evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARC</td>\n",
       "      <td>ARC (AI2 Reasoning Challenge)</td>\n",
       "      <td>Grade-school science questions (7,787) written...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAP</td>\n",
       "      <td>Semi-automatic Attack Prompts</td>\n",
       "      <td>Use the SAP benchmark (https://arxiv.org/abs/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong_reject</td>\n",
       "      <td>Strong Reject</td>\n",
       "      <td>Harness for Strong Reject prompts, including o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ETHICS_original</td>\n",
       "      <td>ETHICS Benchmark</td>\n",
       "      <td>Probes from the ETHICS benchmark.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realtoxicityprompts</td>\n",
       "      <td>Real Toxicity Prompts</td>\n",
       "      <td>Gets the model to output toxic responses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>socialstigma_qa</td>\n",
       "      <td>Social Stigmas</td>\n",
       "      <td>Using the SocialStigmaQA benchmark to capture ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TruthfulQA</td>\n",
       "      <td>TruthfulQA</td>\n",
       "      <td>Measures a model's propensity to reproduce fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>do_not_answer</td>\n",
       "      <td>Do Not Answer</td>\n",
       "      <td>Using the DoNotAnswer benchmark to capture a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Winogrande</td>\n",
       "      <td>Winogrande</td>\n",
       "      <td>An an adversarial and difficult Winograd bench...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>garak</td>\n",
       "      <td>garak</td>\n",
       "      <td>Probes from the open-source garak package.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HarmBench</td>\n",
       "      <td>Evaluate LLMs across harmful behaviours</td>\n",
       "      <td>Using the HarmBench benchmark to evaluate LLMs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MMLU</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>Measures knowledge in zero-shot and few-shot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GSM8k</td>\n",
       "      <td>GSM8k</td>\n",
       "      <td>Grade school math word problems created by hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bbq</td>\n",
       "      <td>Question Answering Bias</td>\n",
       "      <td>Using the BBQ benchmark, Measure bias in quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SafeEval</td>\n",
       "      <td>Safe Eval</td>\n",
       "      <td>Using adversarial prompts designed to test the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>Trivial for humans but difficult for state-of-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CyberSecEval3</td>\n",
       "      <td>Cybersecurity Evaluation (CyberSecEval 3)</td>\n",
       "      <td>Using the CyberSecEval 3 benchmark to assess t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>winobias</td>\n",
       "      <td>Professional Bias</td>\n",
       "      <td>Checks if the model has gender stereotypes abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jiminycricket</td>\n",
       "      <td>Ethics: Simulation</td>\n",
       "      <td>Evaluates the model's ability to identify the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>JBB</td>\n",
       "      <td>JailbreakBench</td>\n",
       "      <td>Using the JailbreakBench benchmark to evaluate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>advglue</td>\n",
       "      <td>Adversarial GLUE</td>\n",
       "      <td>An adversarial version of GLUE benchmark that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       name  \\\n",
       "0                   ARC              ARC (AI2 Reasoning Challenge)   \n",
       "1                   SAP              Semi-automatic Attack Prompts   \n",
       "2         strong_reject                              Strong Reject   \n",
       "3       ETHICS_original                           ETHICS Benchmark   \n",
       "4   realtoxicityprompts                      Real Toxicity Prompts   \n",
       "5       socialstigma_qa                             Social Stigmas   \n",
       "6            TruthfulQA                                 TruthfulQA   \n",
       "7         do_not_answer                              Do Not Answer   \n",
       "8            Winogrande                                 Winogrande   \n",
       "9                 garak                                      garak   \n",
       "10            HarmBench    Evaluate LLMs across harmful behaviours   \n",
       "11                 MMLU                                       MMLU   \n",
       "12                GSM8k                                      GSM8k   \n",
       "13                  bbq                    Question Answering Bias   \n",
       "14             SafeEval                                  Safe Eval   \n",
       "15            HellaSwag                                  HellaSwag   \n",
       "16        CyberSecEval3  Cybersecurity Evaluation (CyberSecEval 3)   \n",
       "17             winobias                          Professional Bias   \n",
       "18        jiminycricket                         Ethics: Simulation   \n",
       "19                  JBB                             JailbreakBench   \n",
       "20              advglue                           Adversarial GLUE   \n",
       "\n",
       "                                          description  \n",
       "0   Grade-school science questions (7,787) written...  \n",
       "1   Use the SAP benchmark (https://arxiv.org/abs/2...  \n",
       "2   Harness for Strong Reject prompts, including o...  \n",
       "3                   Probes from the ETHICS benchmark.  \n",
       "4           Gets the model to output toxic responses.  \n",
       "5   Using the SocialStigmaQA benchmark to capture ...  \n",
       "6   Measures a model's propensity to reproduce fal...  \n",
       "7   Using the DoNotAnswer benchmark to capture a r...  \n",
       "8   An an adversarial and difficult Winograd bench...  \n",
       "9          Probes from the open-source garak package.  \n",
       "10  Using the HarmBench benchmark to evaluate LLMs...  \n",
       "11  Measures knowledge in zero-shot and few-shot s...  \n",
       "12  Grade school math word problems created by hum...  \n",
       "13  Using the BBQ benchmark, Measure bias in quest...  \n",
       "14  Using adversarial prompts designed to test the...  \n",
       "15  Trivial for humans but difficult for state-of-...  \n",
       "16  Using the CyberSecEval 3 benchmark to assess t...  \n",
       "17  Checks if the model has gender stereotypes abo...  \n",
       "18  Evaluates the model's ability to identify the ...  \n",
       "19  Using the JailbreakBench benchmark to evaluate...  \n",
       "20  An adversarial version of GLUE benchmark that ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.harnesses.list(type=\"benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run one or more benchmark, simply supply the name(s) inside the `harnesses` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.evaluations.create(\n",
    "    model_hub=\"openai\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    model_params={\"temperature\": 0},\n",
    "    harnesses=[\"CyberSecEval3\",\"strong_reject\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Harness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
